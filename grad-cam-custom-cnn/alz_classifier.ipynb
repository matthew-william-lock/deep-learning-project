{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124fff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir ~/.kaggle\n",
    "! cp kaggle.json ~/.kaggle/\n",
    "! chmod 600 ~/.kaggle/kaggle.json\n",
    "! kaggle datasets download sachinkumar413/alzheimer-mri-dataset\n",
    "! unzip alzheimer-mri-dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88105b17-f408-4b0e-ab23-4bcb1b4d3150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "\n",
    "cwd = os.path.join(os.getcwd(), 'Dataset')\n",
    "pics = os.listdir(cwd)\n",
    "\n",
    "def data_processing():\n",
    "    #X = np.array()\n",
    "    pics_folders = os.listdir(cwd)\n",
    "    pics = []\n",
    "    for folder in pics_folders:\n",
    "        for pic in os.listdir(os.path.join(cwd, folder)):\n",
    "            pics.append(os.path.join(folder, pic))\n",
    "    c = ['Very_Mild_Demented', 'Non_Demented', 'Mild_Demented', 'Moderate_Demented']\n",
    "    with Image.open(os.path.join(cwd,pics[0])) as im:\n",
    "        X = [np.array(im)]\n",
    "        Y = np.array([c.index(pics[0].split('/')[0])])\n",
    "\n",
    "    for pic in pics[1:]:\n",
    "        try:\n",
    "            with Image.open(os.path.join(cwd,pic)) as im:\n",
    "                X = np.append(X, [np.array(im)], axis=0)\n",
    "                Y = np.append(Y, [c.index(pic.split('/')[0])],axis=0)\n",
    "        except: pass\n",
    "    \n",
    "    Y = tf.keras.utils.to_categorical(Y)\n",
    "    X = X.astype('float32')\n",
    "    X = X/np.max(X)     \n",
    "\n",
    "    return X, Y\n",
    "\n",
    "X, Y = data_processing()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c667489c-b4b4-4c84-ad6f-e13f8a7863da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3 = np.repeat(X[:, :, :, np.newaxis], 3, axis=3)\n",
    "X_1 = X[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01d24444-c1c1-4fe7-933f-eef8b125fdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def partition(X,Y,size=0.2):\n",
    "    return train_test_split(X, Y, test_size=size, random_state=42)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = partition(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad1c4936-20d6-41b5-8f06-75d059bbefb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape_1 (Reshape)         (None, 128, 128, 1)       0         \n",
      "                                                                 \n",
      " first_conv (Conv2D)         (None, 128, 128, 32)      320       \n",
      "                                                                 \n",
      " mid_conv (Conv2D)           (None, 128, 128, 16)      4624      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 63, 63, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 63, 63, 16)        0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 63504)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                1016080   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 68        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,021,092\n",
      "Trainable params: 1,021,092\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def eight_layer_CNN(): \n",
    "    model=tf.keras.Sequential()\n",
    "    \n",
    "    model.add(tf.keras.layers.Reshape(target_shape=(128,128,1), input_shape=(128,128)))\n",
    "    #model.add(tf.keras.layers.ZeroPadding2D(padding=64))\n",
    "    model.add(tf.keras.layers.Conv2D(32, (3, 3), strides=(3, 3), activation=tf.keras.layers.LeakyReLU(alpha=0.01), kernel_initializer='he_uniform', padding='same', input_shape=(128, 128, 1), name='first_conv')) #strides=(2, 2),\n",
    "    #model.add(tf.keras.layers.ZeroPadding2D(padding=2))\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), strides=(3, 3), activation=tf.keras.layers.LeakyReLU(alpha=0.01), kernel_initializer='he_uniform', padding='same', name='mid_conv1'))\n",
    "    #model.add(tf.keras.layers.ZeroPadding2D(padding=2))\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=(1, 1)))\n",
    "    #model.add(tf.keras.layers.ZeroPadding2D(padding=1))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(128, (3, 3), strides=(2, 2), activation=tf.keras.layers.LeakyReLU(alpha=0.01), kernel_initializer='he_uniform', padding='same', name='mid_conv2'))\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=(1, 1)))\n",
    "    #model.add(tf.keras.layers.ZeroPadding2D(padding=1))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(256, (1, 1), strides=(1, 1), activation=tf.keras.layers.LeakyReLU(alpha=0.01), kernel_initializer='he_uniform', padding='same', name='mid_conv3'))\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=(1, 1)))\n",
    "    #model.add(tf.keras.layers.ZeroPadding2D(padding=1))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(512, (1, 1), strides=(1, 1), activation=tf.keras.layers.LeakyReLU(alpha=0.01), kernel_initializer='he_uniform', padding='same', name='mid_conv4'))\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=(1, 1)))\n",
    "    #model.add(tf.keras.layers.ZeroPadding2D(padding=1))\n",
    "\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(1024, (1, 1), strides=(1, 1), activation=tf.keras.layers.LeakyReLU(alpha=0.01), kernel_initializer='he_uniform', padding='same', name='mid_conv5'))\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=1, strides=(1, 1)))\n",
    "    #model.add(tf.keras.layers.ZeroPadding2D(padding=1))\n",
    "\n",
    "    #model.add(tf.keras.layers.Dropout(0.25))\n",
    "    #model.add(tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(128, 128, 1))) #strides=(2, 2),\n",
    "    #model.add(tf.keras.layers.Conv2D(1, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    #model.add(tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    #model.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(100, activation=tf.keras.layers.LeakyReLU(alpha=0.01)))\n",
    "    model.add(tf.keras.layers.Dense(4, activation=\"softmax\"))\n",
    "    return model\n",
    "\n",
    "\n",
    "def define_model(): \n",
    "    model=tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Reshape(target_shape=(128,128,1), input_shape=(128,128)))\n",
    "    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(128, 128, 1), name='first_conv')) #strides=(2, 2),\n",
    "    #model.add(tf.keras.layers.BatchNormalization())\n",
    "    #model.add(tf.keras.layers.Conv2D(2, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', name='mid_conv'))\n",
    "    #model.add(tf.keras.layers.Conv2D(1, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', name='last_conv'))\n",
    "    #model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "    model.add(tf.keras.layers.Dropout(0.25))\n",
    "    #model.add(tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(128, 128, 1))) #strides=(2, 2),\n",
    "    #model.add(tf.keras.layers.Conv2D(1, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    #model.add(tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(16, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(4, activation=\"softmax\"))\n",
    "    return model\n",
    "\n",
    "\n",
    "model = define_model()\n",
    "#opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.9)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt, loss=tf.keras.losses.CategoricalCrossentropy(), metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7c7b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "history = model.fit(X_train, Y_train, epochs=50, batch_size=64, validation_data=(X_test, Y_test), verbose=1, callbacks=[tf.keras.callbacks.EarlyStopping(patience=4), callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20c9fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def summarize_diagnostics(history, model_name):\n",
    "    # plot loss\n",
    "    plt.subplot(211)\n",
    "    plt.title('Cross Entropy Loss')\n",
    "    plt.plot(history.history['loss'], color='royalblue', label='train')\n",
    "    plt.plot(history.history['val_loss'], color='orange', label='test')\n",
    "    plt.legend()\n",
    "    props = dict(boxstyle='round', facecolor='lightgrey', alpha=0.5)\n",
    "    plt.text(0, 0.15, \"min test loss = {}\".format(round(np.min(history.history['val_loss']),3)), fontsize=11, verticalalignment='top', bbox=props)\n",
    "    # plot accuracy\n",
    "    plt.subplot(212)\n",
    "    plt.title('Classification Accuracy')\n",
    "    plt.plot(history.history['categorical_accuracy'], color='royalblue', label='train')\n",
    "    plt.plot(history.history['val_categorical_accuracy'], color='orange', label='test')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend()\n",
    "    plt.text(10.5, 0.55, \"max test accuracy = {}\".format(round(np.max(history.history['val_categorical_accuracy']),3)), fontsize=11, verticalalignment='top', bbox=props)\n",
    "    # save plot to file\n",
    "    plt.subplots_adjust(bottom=-0.5)\n",
    "    plt.savefig(os.path.join(os.getcwd(),'{}_plot.png'.format(model_name)), bbox_inches='tight')\n",
    "    \n",
    "    #plt.close()\n",
    "\n",
    "model_name = \"seq24\"\n",
    "summarize_diagnostics(history, model_name)\n",
    "with open(\"{}_specs.txt\".format(model_name),'w') as f:\n",
    "    model.summary(print_fn=lambda x: f.write(x + '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "22020500",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mild\n",
    "for cnt,y in enumerate(Y):\n",
    "    if np.argmax(y) == 0:\n",
    "        print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ea9feb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#moderate\n",
    "for cnt,y in enumerate(Y):\n",
    "    if np.argmax(y) == 1:\n",
    "        print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d02714d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#non\n",
    "for cnt,y in enumerate(Y):\n",
    "    if np.argmax(y) == 2:\n",
    "        print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3f3cbec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#very mild\n",
    "for cnt,y in enumerate(Y):\n",
    "    if np.argmax(y) == 3:\n",
    "        print(cnt)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff2a791",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import PIL\n",
    "\n",
    "# 4096,1,3200,6336\n",
    "ind = 6338\n",
    "layer = 'mid_conv'\n",
    "grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(layer).output, model.output])\n",
    "img_array = X[ind][np.newaxis, ...]\n",
    "\n",
    "pred_label = np.argmax(model(img_array))\n",
    "correct_label = np.argmax(Y[ind])\n",
    "print(pred_label, correct_label)\n",
    "c = ['Very_Mild_Demented', 'Non_Demented', 'Mild_Demented', 'Moderate_Demented']\n",
    "\n",
    "# gradient of loss\n",
    "with tf.GradientTape() as tape:\n",
    "    inputs = tf.cast(img_array, tf.float32)\n",
    "    (outputs, predictions) = grad_model(inputs)\n",
    "    loss = predictions[:, pred_label]\n",
    "    grads = tape.gradient(loss, outputs)\n",
    "    \n",
    "cast_outputs = tf.cast(outputs > 0, \"float32\")\n",
    "cast_grads = tf.cast(grads > 0, \"float32\")\n",
    "guided_grads = cast_outputs * cast_grads * grads\n",
    "\n",
    "outputs = outputs[0]\n",
    "guided_grads = guided_grads[0]\n",
    "\n",
    "# construct heatmap\n",
    "weights = tf.reduce_mean(guided_grads, axis=(0, 1))\n",
    "cam = tf.reduce_sum(tf.multiply(weights, outputs), axis=-1)\n",
    "(w, h) = (img_array.shape[2], img_array.shape[1])\n",
    "heatmap = cam.numpy().reshape((w, h))\n",
    "numer = heatmap - np.min(heatmap)\n",
    "denom = (heatmap.max() - heatmap.min()) + 10**(-10)\n",
    "heatmap = numer / denom\n",
    "heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "# get color mapping\n",
    "jet = cm.get_cmap(\"jet\")\n",
    "jet_colors = jet(np.arange(256))[:,:3]\n",
    "jet_heatmap = jet_colors[heatmap]\n",
    "#model_name=\"8layer\"\n",
    "# save and display\n",
    "superimposed_img = tf.keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "cam_path = os.path.join(os.getcwd(),\"{}_{}_pic_{}_label_{}_heatmap.jpg\".format(model_name, layer, ind, c[correct_label]))\n",
    "superimposed_img.save(cam_path)\n",
    "display(Image(cam_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
